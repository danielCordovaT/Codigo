{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4cd604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "from unidecode import unidecode\n",
    "import os.path\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "import string\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae9a663",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_to_data=\"data\\\\ADE\\\\\"\n",
    "texts, labels = [], []\n",
    "with open(os.path.join(path_to_data, 'DRUG-AE.rel')) as f:\n",
    "    for line in f:\n",
    "        pubmed_id, text = line.strip().split('|')[:2]\n",
    "        texts.append(unidecode(text))\n",
    "        labels.append(1)\n",
    "\n",
    "with open(os.path.join(path_to_data, 'ADE-NEG.txt')) as f:\n",
    "    for line in f:\n",
    "        pubmed_id, neg = line.strip().split(' ')[:2]\n",
    "        text = ' '.join(line.strip().split(' ')[2:])\n",
    "        texts.append(unidecode(text))\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17e3fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f1fcff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "479dc14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Intravenous azithromycin-induced ototoxicity.\n",
       "1        Immobilization, while Paget's bone disease was...\n",
       "2        Unaccountable severe hypercalcemia in a patien...\n",
       "3        METHODS: We report two cases of pseudoporphyri...\n",
       "5        Naproxen, the most common offender, has been a...\n",
       "                               ...                        \n",
       "23510    Starting with the 8th hospital day, the thromb...\n",
       "23511    At autopsy, the liver was found to be small, s...\n",
       "23512    Physical exam revealed a patient with aphasia,...\n",
       "23513    At the time when the leukemia appeared seven o...\n",
       "23514    The American Society for Regional Anesthesia a...\n",
       "Name: 0, Length: 20895, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0][0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ced57930",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       0\n",
      "0        intravenous azithromycin - induced ototoxicity.\n",
      "1      immobilization, while paget's bone disease was...\n",
      "2      unaccountable severe hypercalcemia in a patien...\n",
      "3      methods : we report two cases of pseudoporphyr...\n",
      "5      naproxen, the most common offender, has been a...\n",
      "...                                                  ...\n",
      "23511  at autopsy, the liver was found to be small, s...\n",
      "23512  physical exam revealed a patient with aphasia,...\n",
      "23513  at the time when the leukemia appeared seven o...\n",
      "23514  the american society for regional anesthesia a...\n",
      "23515  concomitant administration of estradiol result...\n",
      "\n",
      "[20896 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Get the tokenized text back as a string\n",
    "    normalized_text = tokenizer.decode(tokens[\"input_ids\"][0], skip_special_tokens=True)\n",
    "\n",
    "    return normalized_text\n",
    "\n",
    "# Apply the normalization function to the DataFrame\n",
    "df[0] = df[0].apply(normalize_text)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556eea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7*len(texts))\n",
    "val_size =int(0.2*len(texts))\n",
    "test_size = len(texts) - train_size - val_size\n",
    "\n",
    "#Training data  70 %\n",
    "train= df[:train_size]\n",
    "#Validation  20 %  \n",
    "val= df[train_size:train_size+val_size]\n",
    "#Test 10 %\n",
    "test= df[train_size+val_size:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83a97339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0a5d516c004e7e9c97a7cc9d651de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModel\n",
    "model_name=\"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39beb74c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27088\\1630130623.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# Convert logits to predicted labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "tokenized_inputs = tokenizer(df[0].tolist(), truncation=True, padding=True)\n",
    "\n",
    "\n",
    "inputs = tokenizer(df[0][1], return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "logits = outputs.logits\n",
    "# Convert logits to predicted labels\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "predicted_labels = [model.config.id2label[pred.item()] for pred in predictions[0]]\n",
    "\n",
    "# Extract entity spans\n",
    "entity_spans = []\n",
    "start_index = 0\n",
    "for i, label in enumerate(predicted_labels):\n",
    "    if label.startswith(\"B-\"):\n",
    "        entity_span = [text[start_index:i+1]]\n",
    "        start_index = i + 1\n",
    "    elif label.startswith(\"I-\"):\n",
    "        entity_span.append(text[i])\n",
    "    elif entity_span:\n",
    "        entity_spans.append(entity_span)\n",
    "\n",
    "print(entity_spans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "tokens=word_tokenize(text[0])\n",
    "\n",
    "tagged_words=nltk.pos_tag(tokens)\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_text(text[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
